{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1orfNM8t6FCrTL3iJgrk6-AYYIdznsJ0c",
      "authorship_tag": "ABX9TyMpWmzTRVEnxGSFKttv5vR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dansojo/Medical_CV/blob/main/mask%EC%83%9D%EC%84%B1(EfficientNetUNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuCC_A_TR3rp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    DATA_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/A(train)/images\"\n",
        "    MASKS_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/A(train)/masks\"\n",
        "    METADATA_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/HAM10000_metadata\"\n",
        "    SAVE_MODEL_DIR = \"/content/drive/MyDrive/Medical_CV//피부암 분류 및 Segmentation/part3_datasets\"\n",
        "    SAVE_MASKS_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/B(test)/mask이미지(Segmentation_EfficientNetUNet)\"\n",
        "    TEST_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/B(test)/images\"\n",
        "    BATCH_SIZE = 16\n",
        "    IMAGE_SIZE = (224, 224)\n",
        "    NUM_CLASSES = 1  # Binary Segmentation\n",
        "    EPOCHS = 20\n",
        "    LR = 1e-4\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "wsxEGD9GpMvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, metadata, image_transform=None, mask_transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.metadata = metadata\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 이미지 경로 설정\n",
        "        img_name = self.metadata.iloc[idx]['image_id']\n",
        "        image_path = os.path.join(self.image_dir, img_name + \".jpg\")\n",
        "        mask_path = os.path.join(self.mask_dir, img_name + \"_segmentation.png\")\n",
        "\n",
        "        # 이미지와 마스크 로드\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")  # Grayscale로 로드\n",
        "\n",
        "        # 마스크 이진화 (NumPy 배열로 변환 후 0과 1로 구성)\n",
        "        mask = np.array(mask)\n",
        "        mask = (mask > 128).astype(np.float32)  # 이진화 수행\n",
        "\n",
        "        # 변환 적용\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(Image.fromarray(mask * 255))  # NumPy 배열을 PIL 이미지로 변환 후 적용\n",
        "\n",
        "        # 마스크 채널 차원 추가 (필요한 경우)\n",
        "        if len(mask.shape) == 2:\n",
        "            mask = torch.unsqueeze(torch.tensor(mask), dim=0)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "vfKVlDrhqRDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(metadata_path, image_dir):\n",
        "    # 메타데이터 로드\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "    # 실제 파일과 매칭\n",
        "    image_files = set([f.split('.')[0] for f in os.listdir(image_dir)])\n",
        "    metadata = metadata[metadata['image_id'].isin(image_files)]\n",
        "\n",
        "    # 데이터 분할 (7:1.5:1.5)\n",
        "    train_data, temp_data = train_test_split(metadata, test_size=0.3, random_state=42, stratify=metadata['dx'])\n",
        "    val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['dx'])\n",
        "\n",
        "    return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "o656kVHU9uH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_transforms():\n",
        "    # 이미지에만 적용할 변환 (정규화 포함)\n",
        "    image_transform = T.Compose([\n",
        "        T.Resize(Config.IMAGE_SIZE),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "    # 마스크에만 적용할 변환 (정규화 없음)\n",
        "    mask_transform = T.Compose([\n",
        "        T.Resize(Config.IMAGE_SIZE),\n",
        "        T.ToTensor()  # 이진 마스크는 [0, 1] 범위로 변환됨\n",
        "    ])\n",
        "\n",
        "    return image_transform, mask_transform"
      ],
      "metadata": {
        "id": "F2e23XpnqQ_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetUNet(nn.Module):\n",
        "    def __init__(self, input_channels=3, output_channels=1, encoder_name='efficientnet_b0'):\n",
        "        super(EfficientNetUNet, self).__init__()\n",
        "\n",
        "        # EfficientNet 인코더\n",
        "        self.encoder = timm.create_model(\n",
        "            encoder_name,\n",
        "            pretrained=True,\n",
        "            features_only=True,\n",
        "            in_chans=input_channels\n",
        "        )\n",
        "\n",
        "        # 인코더의 채널 수 가져오기\n",
        "        encoder_channels = self.encoder.feature_info.channels()\n",
        "\n",
        "        # 디코더 레이어\n",
        "        self.decoder4 = self._decoder_block(encoder_channels[-1], encoder_channels[-2], 512)\n",
        "        self.decoder3 = self._decoder_block(512, encoder_channels[-3], 256)\n",
        "        self.decoder2 = self._decoder_block(256, encoder_channels[-4], 128)\n",
        "        self.decoder1 = self._decoder_block(128, encoder_channels[-5], 64)\n",
        "\n",
        "        # 최종 출력 레이어\n",
        "        self.final_conv = nn.Conv2d(64, output_channels, kernel_size=1)\n",
        "\n",
        "    def _decoder_block(self, in_channels, skip_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels + skip_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(out_channels, out_channels, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 인코더 통과\n",
        "        features = self.encoder(x)\n",
        "\n",
        "        # 디코더 통과 (스킵 커넥션 활용)\n",
        "        x = self.decoder4(torch.cat([features[-1], F.interpolate(features[-2], size=features[-1].shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "        x = self.decoder3(torch.cat([x, F.interpolate(features[-3], size=x.shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "        x = self.decoder2(torch.cat([x, F.interpolate(features[-4], size=x.shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "        x = self.decoder1(torch.cat([x, F.interpolate(features[-5], size=x.shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "\n",
        "        # 최종 출력\n",
        "        x = self.final_conv(x)\n",
        "        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YRfHEkLyQaTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, num_epochs=20, learning_rate=1e-4, patience=5):\n",
        "    \"\"\"\n",
        "    모델 학습을 수행하는 함수\n",
        "\n",
        "    Args:\n",
        "        model: 학습할 모델\n",
        "        train_loader: 학습 데이터 로더\n",
        "        val_loader: 검증 데이터 로더\n",
        "        device: 학습에 사용할 디바이스 (cuda/cpu)\n",
        "        num_epochs: 학습 에포크 수\n",
        "        learning_rate: 학습률\n",
        "        patience: Early stopping을 위한 patience 값\n",
        "\n",
        "    Returns:\n",
        "        model: 학습된 모델\n",
        "        best_model_state: 가장 좋은 성능을 보인 모델의 가중치\n",
        "        history: 학습 히스토리\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.BCEWithLogitsLoss()  # 손실 함수: BCEWithLogitsLoss\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "    # 학습 관련 변수 초기화\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    early_stopping_counter = 0\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_dice': [],\n",
        "        'val_dice': []\n",
        "    }\n",
        "\n",
        "    print(\"Starting training process...\")\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ----------------------\n",
        "        # Training phase\n",
        "        # ----------------------\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_intersection = 0\n",
        "        train_union = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Training]')\n",
        "\n",
        "        for images, masks in progress_bar:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 손실값 및 Dice coefficient 계산\n",
        "            train_loss += loss.item()\n",
        "            predicted_masks = (outputs > 0).float()  # BCEWithLogitsLoss 사용 시 0 기준\n",
        "            intersection = (predicted_masks * masks).sum()\n",
        "            union = predicted_masks.sum() + masks.sum()\n",
        "            train_intersection += intersection.item()\n",
        "            train_union += union.item()\n",
        "            train_batches += 1\n",
        "\n",
        "            # 프로그레스바 업데이트\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'dice': f'{(2 * intersection / (union + 1e-8)).item():.4f}'\n",
        "            })\n",
        "\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        avg_train_dice = (2 * train_intersection) / (train_union + 1e-8)\n",
        "\n",
        "        # ----------------------\n",
        "        # Validation phase\n",
        "        # ----------------------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_intersection = 0\n",
        "        val_union = 0\n",
        "        val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Validation]')\n",
        "\n",
        "            for images, masks in progress_bar:\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                predicted_masks = (outputs > 0).float()\n",
        "                intersection = (predicted_masks * masks).sum()\n",
        "                union = predicted_masks.sum() + masks.sum()\n",
        "                val_intersection += intersection.item()\n",
        "                val_union += union.item()\n",
        "                val_batches += 1\n",
        "\n",
        "                progress_bar.set_postfix({\n",
        "                    'val_loss': f'{loss.item():.4f}',\n",
        "                    'val_dice': f'{(2 * intersection / (union + 1e-8)).item():.4f}'\n",
        "                })\n",
        "\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        avg_val_dice = (2 * val_intersection) / (val_union + 1e-8)\n",
        "\n",
        "        # 히스토리 업데이트\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['train_dice'].append(avg_train_dice)\n",
        "        history['val_dice'].append(avg_val_dice)\n",
        "\n",
        "        # 결과 출력\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Dice: {avg_train_dice:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Dice: {avg_val_dice:.4f}\")\n",
        "\n",
        "        # 학습률 스케줄러 호출\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # 최적 모델 저장\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            early_stopping_counter = 0\n",
        "            print(f\"Best model updated at epoch {epoch+1}\")\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "\n",
        "        # Early stopping 체크\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "        # 중간 체크포인트 저장 (5 에포크마다)\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint_path = os.path.join(\n",
        "                Config.SAVE_MODEL_DIR,\n",
        "                f'checkpoint_epoch_{epoch+1}.pth'\n",
        "            )\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "                'train_dice': avg_train_dice,\n",
        "                'val_dice': avg_val_dice,\n",
        "                'history': history\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, best_model_state, history\n"
      ],
      "metadata": {
        "id": "mC4FxCsjUOQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(save_dir, model_state, file_name=\"best_model.pth\"):\n",
        "    \"\"\"\n",
        "    모델 가중치를 저장하는 함수.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, file_name)\n",
        "    torch.save(model_state, save_path)\n",
        "    print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "id": "6J1KK-_H5J26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 분리\n",
        "train_data, val_data, test_data = split_data(Config.METADATA_DIR, Config.DATA_DIR)\n",
        "full_data = pd.concat([train_data, val_data, test_data])\n",
        "\n",
        "# 2. 데이터 로드 및 변환\n",
        "image_transform, mask_transform = get_data_transforms()\n",
        "\n",
        "train_dataset = ImageDataset(Config.DATA_DIR, Config.MASKS_DIR, train_data, image_transform, mask_transform)\n",
        "val_dataset = ImageDataset(Config.DATA_DIR, Config.MASKS_DIR, val_data, image_transform, mask_transform)\n",
        "test_dataset = ImageDataset(Config.DATA_DIR, Config.MASKS_DIR, test_data, image_transform, mask_transform)\n",
        "full_dataset = ImageDataset(Config.DATA_DIR,Config.MASKS_DIR, full_data, image_transform, mask_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "full_loader = DataLoader(full_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "yLjAVmE_5PnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, masks in train_loader:\n",
        "    print(f\"Image batch shape: {images.shape}\")  # 이미지 형태 출력\n",
        "    print(f\"Mask batch shape: {masks.shape}\")    # 마스크 형태 출력\n",
        "    break  # 첫 번째 배치만 출력하고 종료"
      ],
      "metadata": {
        "id": "ee7rwJos5Shj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2876db85-23cd-4049-c6b1-5515aba523c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape: torch.Size([16, 3, 224, 224])\n",
            "Mask batch shape: torch.Size([16, 1, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "316u6s3w5UY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4b10f0-d9c2-40af-f18d-fcd19aad3ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 학습\n",
        "model = EfficientNetUNet(input_channels=3, output_channels=1)\n",
        "trained_model, best_model_state, history = train_model(model, train_loader, val_loader, Config.DEVICE)\n",
        "\n",
        "# 최적 모델 저장\n",
        "save_path = os.path.join(Config.SAVE_MODEL_DIR, \"best_model_Atten.pth\")\n",
        "torch.save(best_model_state, save_path)\n",
        "print(f\"Best model saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KGCiwiFlTJM",
        "outputId": "4e36e4ad-dfe2-41a5-e421-926201c07ab4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:timm.models._builder:Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training process...\n",
            "Training on device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20 [Training]: 100%|██████████| 395/395 [1:40:33<00:00, 15.27s/it, loss=-2635.4277, dice=1.9693]\n",
            "Epoch 1/20 [Validation]:  62%|██████▏   | 53/85 [14:30<08:00, 15.01s/it, val_loss=-2439.6760, val_dice=1.9659]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train vs Validation Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Train vs Validation Dice Coefficient\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history['train_dice'], label='Train Dice')\n",
        "plt.plot(history['val_dice'], label='Val Dice')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.title('Train vs Validation Dice Coefficient')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6y1TcSegUaSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_id = self.image_files[idx].split('.')[0]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_id"
      ],
      "metadata": {
        "id": "8D90BXXO5juH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_masks(model, data_loader, save_dir, device):\n",
        "    model.eval()\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"Generating masks\"):\n",
        "            images, image_ids = batch\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            predictions = torch.sigmoid(outputs) > 0.5  # sigmoid 적용 후 이진화\n",
        "\n",
        "            for pred, img_id in zip(predictions, image_ids):\n",
        "                mask = pred.squeeze().cpu().numpy() * 255\n",
        "                mask_path = os.path.join(save_dir, f\"{img_id}_generated.png\")\n",
        "                cv2.imwrite(mask_path, mask.astype(np.uint8))\n",
        "\n",
        "    print(f\"Masks saved to {save_dir}\")"
      ],
      "metadata": {
        "id": "0TG-pHiZUdT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 이미지 경로\n",
        "test_image_dir = Config.TEST_DIR\n",
        "\n",
        "# 변환 정의 (학습에 사용한 것과 동일하게 적용)\n",
        "test_transform = T.Compose([\n",
        "    T.Resize(Config.IMAGE_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# 테스트 데이터셋 및 데이터 로더 생성\n",
        "test_dataset = TestImageDataset(test_image_dir, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2,\n",
        "                        pin_memory=True)\n",
        "\n",
        "# 학습된 모델로 테스트 데이터에 대한 마스크 생성 및 저장\n",
        "generate_and_save_masks(trained_model, test_loader, Config.SAVE_MASKS_DIR, Config.DEVICE)"
      ],
      "metadata": {
        "id": "M4nb5r9gUdRG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}