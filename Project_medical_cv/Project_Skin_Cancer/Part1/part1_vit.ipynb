{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1SUoiYqb2J8mwE0LE9IzbHKeNA_AG1YuB",
      "authorship_tag": "ABX9TyP/shBXWkhkJ1V350Ki/B2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dansojo/Medical_CV/blob/main/part1_vit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y4sVKoxj5jj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import Dropout\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 설정 값\n",
        "class Config:\n",
        "    TRAIN_PATH = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/part1_datasets/train_dataset.pt\"\n",
        "    VAL_PATH = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/part1_datasets/val_dataset.pt\"\n",
        "    TEST_PATH = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/part1_datasets/test_dataset.pt\"\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 20\n",
        "    LR = 0.001\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "nyPpI8s-j-FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 함수\n",
        "def load_data(train_path, val_path, test_path):\n",
        "    train_images, train_labels = torch.load(train_path)\n",
        "    val_images, val_labels = torch.load(val_path)\n",
        "    test_images, test_labels = torch.load(test_path)\n",
        "\n",
        "    train_dataset = TensorDataset(train_images, train_labels)\n",
        "    val_dataset = TensorDataset(val_images, val_labels)\n",
        "    test_dataset = TensorDataset(test_images, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "iFM9IMSWj-MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ViT 모델 정의\n",
        "def get_vit_model(num_classes=7):\n",
        "    weights = ViT_B_16_Weights.DEFAULT  # 최신 가중치 사용\n",
        "    model = vit_b_16(weights=weights)  # pretrained 대신 weights 사용\n",
        "    model.heads.head = nn.Sequential(\n",
        "    Dropout(p=0.5),\n",
        "    nn.Linear(model.heads.head.in_features, num_classes)\n",
        "    )\n",
        "    return model.to(Config.DEVICE)"
      ],
      "metadata": {
        "id": "9yuKUuGcj-O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, train_loader, val_loader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=Config.LR)\n",
        "\n",
        "    for epoch in range(Config.EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{Config.EPOCHS}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_accuracy = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)  # Validation Loss 계산\n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_accuracy.append(accuracy_score(labels.cpu(), preds.cpu()))\n",
        "        # Training/Validation Loss와 Validation Accuracy 출력\n",
        "        print(f\"Epoch [{epoch+1}/{Config.EPOCHS}], \"\n",
        "              f\"Training Loss: {running_loss/len(train_loader):.4f}, \"\n",
        "              f\"Validation Loss: {val_loss/len(val_loader):.4f}, \"\n",
        "              f\"Validation Accuracy: {sum(val_accuracy)/len(val_accuracy):.4f}\")"
      ],
      "metadata": {
        "id": "IqDPEAqPj-Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 함수\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 평가 지표\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")"
      ],
      "metadata": {
        "id": "X5k2yX2Fj-Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행\n",
        "train_loader, val_loader, test_loader = load_data(Config.TRAIN_PATH, Config.VAL_PATH, Config.TEST_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXPsJ0Y_j-Xs",
        "outputId": "33963c2a-d41b-4c37-bdb8-28c3ac9628a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-76246b475679>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_images, train_labels = torch.load(train_path)\n",
            "<ipython-input-3-76246b475679>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  val_images, val_labels = torch.load(val_path)\n",
            "<ipython-input-3-76246b475679>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_images, test_labels = torch.load(test_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_vit_model()\n",
        "train_model(model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP3gLb8aqA-A",
        "outputId": "562a63f6-354c-49cf-923a-0f7b6c62c563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:02<00:00, 123MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 1.1821\n",
            "Epoch [1/20], Training Loss: 1.1821, Validation Loss: 1.0292, Validation Accuracy: 0.6904\n",
            "Epoch [2/20], Loss: 1.0750\n",
            "Epoch [2/20], Training Loss: 1.0750, Validation Loss: 0.8979, Validation Accuracy: 0.6904\n",
            "Epoch [3/20], Loss: 1.0019\n",
            "Epoch [3/20], Training Loss: 1.0019, Validation Loss: 0.9172, Validation Accuracy: 0.7031\n",
            "Epoch [4/20], Loss: 0.9883\n",
            "Epoch [4/20], Training Loss: 0.9883, Validation Loss: 0.8796, Validation Accuracy: 0.6904\n",
            "Epoch [5/20], Loss: 0.9491\n",
            "Epoch [5/20], Training Loss: 0.9491, Validation Loss: 0.8786, Validation Accuracy: 0.6904\n",
            "Epoch [6/20], Loss: 0.9160\n",
            "Epoch [6/20], Training Loss: 0.9160, Validation Loss: 0.8546, Validation Accuracy: 0.6934\n",
            "Epoch [7/20], Loss: 0.9211\n",
            "Epoch [7/20], Training Loss: 0.9211, Validation Loss: 0.8475, Validation Accuracy: 0.6914\n",
            "Epoch [8/20], Loss: 0.8948\n",
            "Epoch [8/20], Training Loss: 0.8948, Validation Loss: 0.8239, Validation Accuracy: 0.6953\n",
            "Epoch [9/20], Loss: 0.8921\n",
            "Epoch [9/20], Training Loss: 0.8921, Validation Loss: 0.7913, Validation Accuracy: 0.7256\n",
            "Epoch [10/20], Loss: 0.8788\n",
            "Epoch [10/20], Training Loss: 0.8788, Validation Loss: 0.8115, Validation Accuracy: 0.7158\n",
            "Epoch [11/20], Loss: 0.8593\n",
            "Epoch [11/20], Training Loss: 0.8593, Validation Loss: 0.7863, Validation Accuracy: 0.7158\n",
            "Epoch [12/20], Loss: 0.8560\n",
            "Epoch [12/20], Training Loss: 0.8560, Validation Loss: 0.8055, Validation Accuracy: 0.7090\n",
            "Epoch [13/20], Loss: 0.8416\n",
            "Epoch [13/20], Training Loss: 0.8416, Validation Loss: 0.7655, Validation Accuracy: 0.7314\n",
            "Epoch [14/20], Loss: 0.8241\n",
            "Epoch [14/20], Training Loss: 0.8241, Validation Loss: 0.7654, Validation Accuracy: 0.7256\n",
            "Epoch [15/20], Loss: 0.8111\n",
            "Epoch [15/20], Training Loss: 0.8111, Validation Loss: 0.7428, Validation Accuracy: 0.7373\n",
            "Epoch [16/20], Loss: 0.7966\n",
            "Epoch [16/20], Training Loss: 0.7966, Validation Loss: 0.9091, Validation Accuracy: 0.7080\n",
            "Epoch [17/20], Loss: 0.8095\n",
            "Epoch [17/20], Training Loss: 0.8095, Validation Loss: 0.7729, Validation Accuracy: 0.6836\n",
            "Epoch [18/20], Loss: 0.7842\n",
            "Epoch [18/20], Training Loss: 0.7842, Validation Loss: 0.7322, Validation Accuracy: 0.7373\n",
            "Epoch [19/20], Loss: 0.7789\n",
            "Epoch [19/20], Training Loss: 0.7789, Validation Loss: 0.7788, Validation Accuracy: 0.7412\n",
            "Epoch [20/20], Loss: 0.7642\n",
            "Epoch [20/20], Training Loss: 0.7642, Validation Loss: 0.7176, Validation Accuracy: 0.7432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "def save_entire_model(model, save_path):\n",
        "    torch.save(model, save_path)\n",
        "    print(f\"Entire model saved to {save_path}\")\n",
        "\n",
        "# 예시 - 학습 후 저장\n",
        "save_path = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/part1_datasets/part1_vit_model.pth\"\n",
        "save_entire_model(model, save_path)"
      ],
      "metadata": {
        "id": "_v982AEuAfGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c181f2-6e8f-4bd1-cbb8-0c95cce5b023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entire model saved to /content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/part1_datasets/part1_vit_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "id": "QF8twu-Qp9Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06971857-8115-42e6-d02c-6d4098364803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7260\n",
            "F1 Score: 0.6934\n",
            "Confusion Matrix:\n",
            "[[ 55  48   0   3   0   3   4]\n",
            " [ 32 639   0   9   0   2   5]\n",
            " [  1   5   0   0   0   3   2]\n",
            " [ 21  50   0  15   0   0   1]\n",
            " [  1  10   0   0   2   0   0]\n",
            " [ 17  15   0   1   0  10  10]\n",
            " [ 11  13   0   2   0   5   5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix 시각화 함수\n",
        "def plot_confusion_matrix(true_labels, predicted_labels, class_names):\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# 클래스 이름 정의\n",
        "class_names = [\"bkl\", \"nv\", \"df\", \"mel\", \"vasc\", \"bcc\", \"akiec\"]\n",
        "\n",
        "# 모델 평가 및 Confusion Matrix 생성\n",
        "def evaluate_and_plot_confusion_matrix(model, test_loader, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)  # 예측값\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Confusion Matrix 시각화\n",
        "    plot_confusion_matrix(all_labels, all_preds, class_names)\n",
        "\n",
        "    # 테스트 정확도 출력\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "FNQjVvmA-SU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_and_plot_confusion_matrix(model, test_loader, class_names)"
      ],
      "metadata": {
        "id": "aVIcjMCi-SQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 지표 시각화 함수\n",
        "def plot_classification_metrics(true_labels, predicted_labels, class_names):\n",
        "    # Classification Report 생성\n",
        "    report = classification_report(true_labels, predicted_labels, target_names=class_names, output_dict=True)\n",
        "\n",
        "    # Precision, Recall, F1 Score 추출\n",
        "    metrics = ['precision', 'recall', 'f1-score']\n",
        "    scores = {metric: [report[label][metric] for label in class_names] for metric in metrics}\n",
        "\n",
        "    # 그래프 그리기\n",
        "    x = np.arange(len(class_names))\n",
        "    width = 0.2\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.bar(x + i * width, scores[metric], width, label=metric)\n",
        "\n",
        "    plt.xlabel('Classes')\n",
        "    plt.ylabel('Scores')\n",
        "    plt.title('Classification Metrics by Class')\n",
        "    plt.xticks(x + width, class_names, rotation=45)\n",
        "    plt.ylim(0, 1)  # 점수 범위를 0~1로 고정\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 클래스 이름 정의\n",
        "class_names = [\"bkl\", \"nv\", \"df\", \"mel\", \"vasc\", \"bcc\", \"akiec\"]\n",
        "\n",
        "# 모델 평가 및 성능 지표 시각화\n",
        "def evaluate_and_plot_metrics(model, test_loader, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)  # 예측값\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 성능 지표 그래프 그리기\n",
        "    plot_classification_metrics(all_labels, all_preds, class_names)\n",
        "\n",
        "    # Classification Report 출력\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n"
      ],
      "metadata": {
        "id": "8moy0oPb-SCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_and_plot_metrics(model, test_loader, class_names)"
      ],
      "metadata": {
        "id": "JM7iMuYl-R98"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
