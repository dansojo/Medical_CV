{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1AtVWYJD7jq3PAreUKb14OFO7vuAugiwG",
      "authorship_tag": "ABX9TyPFfKkWKQjFHV898NJkWvvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc3e5098b3b342af89cf8d6f4a094f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cc7f9953c2c4218a832612d81101d27",
              "IPY_MODEL_69ab3ea182394f5c9346cdbeebe32b28",
              "IPY_MODEL_a27b449cdcff4500afc6a5b445a165f7"
            ],
            "layout": "IPY_MODEL_f5bda6d549144c7a896da47c1c8304d4"
          }
        },
        "9cc7f9953c2c4218a832612d81101d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba69654b79594a9b997569a5682e919a",
            "placeholder": "​",
            "style": "IPY_MODEL_9a5cc6ef7c494cba8f109dbc2f1b62a9",
            "value": "model.safetensors: 100%"
          }
        },
        "69ab3ea182394f5c9346cdbeebe32b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37170b1fedfc497b9e3cfb39450c585f",
            "max": 5135772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bed56802899b4339bfbdbea51a79718e",
            "value": 5135772
          }
        },
        "a27b449cdcff4500afc6a5b445a165f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0de2dfde2e734eb8877414f65c1a489b",
            "placeholder": "​",
            "style": "IPY_MODEL_f50d08f589944390bffccab21d6e8c08",
            "value": " 5.14M/5.14M [00:00&lt;00:00, 20.7MB/s]"
          }
        },
        "f5bda6d549144c7a896da47c1c8304d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba69654b79594a9b997569a5682e919a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a5cc6ef7c494cba8f109dbc2f1b62a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37170b1fedfc497b9e3cfb39450c585f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed56802899b4339bfbdbea51a79718e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0de2dfde2e734eb8877414f65c1a489b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50d08f589944390bffccab21d6e8c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dansojo/Medical_CV/blob/main/mask%EC%83%9D%EC%84%B1(TransformerUNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuCC_A_TR3rp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(timm.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml7T1gqqe56M",
        "outputId": "134e7523-33bf-4403-c562-aab50d6b99df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aimv2_1b_patch14_224', 'aimv2_1b_patch14_336', 'aimv2_1b_patch14_448', 'aimv2_3b_patch14_224', 'aimv2_3b_patch14_336', 'aimv2_3b_patch14_448', 'aimv2_huge_patch14_224', 'aimv2_huge_patch14_336', 'aimv2_huge_patch14_448', 'aimv2_large_patch14_224', 'aimv2_large_patch14_336', 'aimv2_large_patch14_448', 'bat_resnext26ts', 'beit_base_patch16_224', 'beit_base_patch16_384', 'beit_large_patch16_224', 'beit_large_patch16_384', 'beit_large_patch16_512', 'beitv2_base_patch16_224', 'beitv2_large_patch16_224', 'botnet26t_256', 'botnet50ts_256', 'caformer_b36', 'caformer_m36', 'caformer_s18', 'caformer_s36', 'cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'coat_lite_medium', 'coat_lite_medium_384', 'coat_lite_mini', 'coat_lite_small', 'coat_lite_tiny', 'coat_mini', 'coat_small', 'coat_tiny', 'coatnet_0_224', 'coatnet_0_rw_224', 'coatnet_1_224', 'coatnet_1_rw_224', 'coatnet_2_224', 'coatnet_2_rw_224', 'coatnet_3_224', 'coatnet_3_rw_224', 'coatnet_4_224', 'coatnet_5_224', 'coatnet_bn_0_rw_224', 'coatnet_nano_cc_224', 'coatnet_nano_rw_224', 'coatnet_pico_rw_224', 'coatnet_rmlp_0_rw_224', 'coatnet_rmlp_1_rw2_224', 'coatnet_rmlp_1_rw_224', 'coatnet_rmlp_2_rw_224', 'coatnet_rmlp_2_rw_384', 'coatnet_rmlp_3_rw_224', 'coatnet_rmlp_nano_rw_224', 'coatnext_nano_rw_224', 'convformer_b36', 'convformer_m36', 'convformer_s18', 'convformer_s36', 'convit_base', 'convit_small', 'convit_tiny', 'convmixer_768_32', 'convmixer_1024_20_ks9_p14', 'convmixer_1536_20', 'convnext_atto', 'convnext_atto_ols', 'convnext_atto_rms', 'convnext_base', 'convnext_femto', 'convnext_femto_ols', 'convnext_large', 'convnext_large_mlp', 'convnext_nano', 'convnext_nano_ols', 'convnext_pico', 'convnext_pico_ols', 'convnext_small', 'convnext_tiny', 'convnext_tiny_hnf', 'convnext_xlarge', 'convnext_xxlarge', 'convnext_zepto_rms', 'convnext_zepto_rms_ols', 'convnextv2_atto', 'convnextv2_base', 'convnextv2_femto', 'convnextv2_huge', 'convnextv2_large', 'convnextv2_nano', 'convnextv2_pico', 'convnextv2_small', 'convnextv2_tiny', 'crossvit_9_240', 'crossvit_9_dagger_240', 'crossvit_15_240', 'crossvit_15_dagger_240', 'crossvit_15_dagger_408', 'crossvit_18_240', 'crossvit_18_dagger_240', 'crossvit_18_dagger_408', 'crossvit_base_240', 'crossvit_small_240', 'crossvit_tiny_240', 'cs3darknet_focus_l', 'cs3darknet_focus_m', 'cs3darknet_focus_s', 'cs3darknet_focus_x', 'cs3darknet_l', 'cs3darknet_m', 'cs3darknet_s', 'cs3darknet_x', 'cs3edgenet_x', 'cs3se_edgenet_x', 'cs3sedarknet_l', 'cs3sedarknet_x', 'cs3sedarknet_xdw', 'cspdarknet53', 'cspresnet50', 'cspresnet50d', 'cspresnet50w', 'cspresnext50', 'darknet17', 'darknet21', 'darknet53', 'darknetaa53', 'davit_base', 'davit_base_fl', 'davit_giant', 'davit_huge', 'davit_huge_fl', 'davit_large', 'davit_small', 'davit_tiny', 'deit3_base_patch16_224', 'deit3_base_patch16_384', 'deit3_huge_patch14_224', 'deit3_large_patch16_224', 'deit3_large_patch16_384', 'deit3_medium_patch16_224', 'deit3_small_patch16_224', 'deit3_small_patch16_384', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenet264d', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn48b', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'eca_botnext26ts_256', 'eca_halonext26ts', 'eca_nfnet_l0', 'eca_nfnet_l1', 'eca_nfnet_l2', 'eca_nfnet_l3', 'eca_resnet33ts', 'eca_resnext26ts', 'eca_vovnet39b', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet200d', 'ecaresnet269d', 'ecaresnetlight', 'ecaresnext26t_32x4d', 'ecaresnext50t_32x4d', 'edgenext_base', 'edgenext_small', 'edgenext_small_rw', 'edgenext_x_small', 'edgenext_xx_small', 'efficientformer_l1', 'efficientformer_l3', 'efficientformer_l7', 'efficientformerv2_l', 'efficientformerv2_s0', 'efficientformerv2_s1', 'efficientformerv2_s2', 'efficientnet_b0', 'efficientnet_b0_g8_gn', 'efficientnet_b0_g16_evos', 'efficientnet_b0_gn', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_g8_gn', 'efficientnet_b3_gn', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_b8', 'efficientnet_blur_b0', 'efficientnet_cc_b0_4e', 'efficientnet_cc_b0_8e', 'efficientnet_cc_b1_8e', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_h_b5', 'efficientnet_l2', 'efficientnet_lite0', 'efficientnet_lite1', 'efficientnet_lite2', 'efficientnet_lite3', 'efficientnet_lite4', 'efficientnet_x_b3', 'efficientnet_x_b5', 'efficientnetv2_l', 'efficientnetv2_m', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'efficientnetv2_rw_t', 'efficientnetv2_s', 'efficientnetv2_xl', 'efficientvit_b0', 'efficientvit_b1', 'efficientvit_b2', 'efficientvit_b3', 'efficientvit_l1', 'efficientvit_l2', 'efficientvit_l3', 'efficientvit_m0', 'efficientvit_m1', 'efficientvit_m2', 'efficientvit_m3', 'efficientvit_m4', 'efficientvit_m5', 'ese_vovnet19b_dw', 'ese_vovnet19b_slim', 'ese_vovnet19b_slim_dw', 'ese_vovnet39b', 'ese_vovnet39b_evos', 'ese_vovnet57b', 'ese_vovnet99b', 'eva02_base_patch14_224', 'eva02_base_patch14_448', 'eva02_base_patch16_clip_224', 'eva02_enormous_patch14_clip_224', 'eva02_large_patch14_224', 'eva02_large_patch14_448', 'eva02_large_patch14_clip_224', 'eva02_large_patch14_clip_336', 'eva02_small_patch14_224', 'eva02_small_patch14_336', 'eva02_tiny_patch14_224', 'eva02_tiny_patch14_336', 'eva_giant_patch14_224', 'eva_giant_patch14_336', 'eva_giant_patch14_560', 'eva_giant_patch14_clip_224', 'eva_large_patch14_196', 'eva_large_patch14_336', 'fastvit_ma36', 'fastvit_mci0', 'fastvit_mci1', 'fastvit_mci2', 'fastvit_s12', 'fastvit_sa12', 'fastvit_sa24', 'fastvit_sa36', 'fastvit_t8', 'fastvit_t12', 'fbnetc_100', 'fbnetv3_b', 'fbnetv3_d', 'fbnetv3_g', 'flexivit_base', 'flexivit_large', 'flexivit_small', 'focalnet_base_lrf', 'focalnet_base_srf', 'focalnet_huge_fl3', 'focalnet_huge_fl4', 'focalnet_large_fl3', 'focalnet_large_fl4', 'focalnet_small_lrf', 'focalnet_small_srf', 'focalnet_tiny_lrf', 'focalnet_tiny_srf', 'focalnet_xlarge_fl3', 'focalnet_xlarge_fl4', 'gc_efficientnetv2_rw_t', 'gcresnet33ts', 'gcresnet50t', 'gcresnext26ts', 'gcresnext50ts', 'gcvit_base', 'gcvit_small', 'gcvit_tiny', 'gcvit_xtiny', 'gcvit_xxtiny', 'gernet_l', 'gernet_m', 'gernet_s', 'ghostnet_050', 'ghostnet_100', 'ghostnet_130', 'ghostnetv2_100', 'ghostnetv2_130', 'ghostnetv2_160', 'gmixer_12_224', 'gmixer_24_224', 'gmlp_b16_224', 'gmlp_s16_224', 'gmlp_ti16_224', 'halo2botnet50ts_256', 'halonet26t', 'halonet50ts', 'halonet_h1', 'haloregnetz_b', 'hardcorenas_a', 'hardcorenas_b', 'hardcorenas_c', 'hardcorenas_d', 'hardcorenas_e', 'hardcorenas_f', 'hgnet_base', 'hgnet_small', 'hgnet_tiny', 'hgnetv2_b0', 'hgnetv2_b1', 'hgnetv2_b2', 'hgnetv2_b3', 'hgnetv2_b4', 'hgnetv2_b5', 'hgnetv2_b6', 'hiera_base_224', 'hiera_base_abswin_256', 'hiera_base_plus_224', 'hiera_huge_224', 'hiera_large_224', 'hiera_small_224', 'hiera_small_abswin_256', 'hiera_tiny_224', 'hieradet_small', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w18_ssld', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w48_ssld', 'hrnet_w64', 'inception_next_atto', 'inception_next_base', 'inception_next_small', 'inception_next_tiny', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'lambda_resnet26rpt_256', 'lambda_resnet26t', 'lambda_resnet50ts', 'lamhalobotnet50ts_256', 'lcnet_035', 'lcnet_050', 'lcnet_075', 'lcnet_100', 'lcnet_150', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'legacy_xception', 'levit_128', 'levit_128s', 'levit_192', 'levit_256', 'levit_256d', 'levit_384', 'levit_384_s8', 'levit_512', 'levit_512_s8', 'levit_512d', 'levit_conv_128', 'levit_conv_128s', 'levit_conv_192', 'levit_conv_256', 'levit_conv_256d', 'levit_conv_384', 'levit_conv_384_s8', 'levit_conv_512', 'levit_conv_512_s8', 'levit_conv_512d', 'mambaout_base', 'mambaout_base_plus_rw', 'mambaout_base_short_rw', 'mambaout_base_tall_rw', 'mambaout_base_wide_rw', 'mambaout_femto', 'mambaout_kobe', 'mambaout_small', 'mambaout_small_rw', 'mambaout_tiny', 'maxvit_base_tf_224', 'maxvit_base_tf_384', 'maxvit_base_tf_512', 'maxvit_large_tf_224', 'maxvit_large_tf_384', 'maxvit_large_tf_512', 'maxvit_nano_rw_256', 'maxvit_pico_rw_256', 'maxvit_rmlp_base_rw_224', 'maxvit_rmlp_base_rw_384', 'maxvit_rmlp_nano_rw_256', 'maxvit_rmlp_pico_rw_256', 'maxvit_rmlp_small_rw_224', 'maxvit_rmlp_small_rw_256', 'maxvit_rmlp_tiny_rw_256', 'maxvit_small_tf_224', 'maxvit_small_tf_384', 'maxvit_small_tf_512', 'maxvit_tiny_pm_256', 'maxvit_tiny_rw_224', 'maxvit_tiny_rw_256', 'maxvit_tiny_tf_224', 'maxvit_tiny_tf_384', 'maxvit_tiny_tf_512', 'maxvit_xlarge_tf_224', 'maxvit_xlarge_tf_384', 'maxvit_xlarge_tf_512', 'maxxvit_rmlp_nano_rw_256', 'maxxvit_rmlp_small_rw_256', 'maxxvit_rmlp_tiny_rw_256', 'maxxvitv2_nano_rw_256', 'maxxvitv2_rmlp_base_rw_224', 'maxxvitv2_rmlp_base_rw_384', 'maxxvitv2_rmlp_large_rw_224', 'mixer_b16_224', 'mixer_b32_224', 'mixer_l16_224', 'mixer_l32_224', 'mixer_s16_224', 'mixer_s32_224', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mixnet_xxl', 'mnasnet_050', 'mnasnet_075', 'mnasnet_100', 'mnasnet_140', 'mnasnet_small', 'mobilenet_edgetpu_100', 'mobilenet_edgetpu_v2_l', 'mobilenet_edgetpu_v2_m', 'mobilenet_edgetpu_v2_s', 'mobilenet_edgetpu_v2_xs', 'mobilenetv1_100', 'mobilenetv1_100h', 'mobilenetv1_125', 'mobilenetv2_035', 'mobilenetv2_050', 'mobilenetv2_075', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_075', 'mobilenetv3_large_100', 'mobilenetv3_large_150d', 'mobilenetv3_rw', 'mobilenetv3_small_050', 'mobilenetv3_small_075', 'mobilenetv3_small_100', 'mobilenetv4_conv_aa_large', 'mobilenetv4_conv_aa_medium', 'mobilenetv4_conv_blur_medium', 'mobilenetv4_conv_large', 'mobilenetv4_conv_medium', 'mobilenetv4_conv_small', 'mobilenetv4_conv_small_035', 'mobilenetv4_conv_small_050', 'mobilenetv4_hybrid_large', 'mobilenetv4_hybrid_large_075', 'mobilenetv4_hybrid_medium', 'mobilenetv4_hybrid_medium_075', 'mobileone_s0', 'mobileone_s1', 'mobileone_s2', 'mobileone_s3', 'mobileone_s4', 'mobilevit_s', 'mobilevit_xs', 'mobilevit_xxs', 'mobilevitv2_050', 'mobilevitv2_075', 'mobilevitv2_100', 'mobilevitv2_125', 'mobilevitv2_150', 'mobilevitv2_175', 'mobilevitv2_200', 'mvitv2_base', 'mvitv2_base_cls', 'mvitv2_huge_cls', 'mvitv2_large', 'mvitv2_large_cls', 'mvitv2_small', 'mvitv2_small_cls', 'mvitv2_tiny', 'nasnetalarge', 'nest_base', 'nest_base_jx', 'nest_small', 'nest_small_jx', 'nest_tiny', 'nest_tiny_jx', 'nextvit_base', 'nextvit_large', 'nextvit_small', 'nf_ecaresnet26', 'nf_ecaresnet50', 'nf_ecaresnet101', 'nf_regnet_b0', 'nf_regnet_b1', 'nf_regnet_b2', 'nf_regnet_b3', 'nf_regnet_b4', 'nf_regnet_b5', 'nf_resnet26', 'nf_resnet50', 'nf_resnet101', 'nf_seresnet26', 'nf_seresnet50', 'nf_seresnet101', 'nfnet_f0', 'nfnet_f1', 'nfnet_f2', 'nfnet_f3', 'nfnet_f4', 'nfnet_f5', 'nfnet_f6', 'nfnet_f7', 'nfnet_l0', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'pnasnet5large', 'poolformer_m36', 'poolformer_m48', 'poolformer_s12', 'poolformer_s24', 'poolformer_s36', 'poolformerv2_m36', 'poolformerv2_m48', 'poolformerv2_s12', 'poolformerv2_s24', 'poolformerv2_s36', 'pvt_v2_b0', 'pvt_v2_b1', 'pvt_v2_b2', 'pvt_v2_b2_li', 'pvt_v2_b3', 'pvt_v2_b4', 'pvt_v2_b5', 'rdnet_base', 'rdnet_large', 'rdnet_small', 'rdnet_tiny', 'regnetv_040', 'regnetv_064', 'regnetx_002', 'regnetx_004', 'regnetx_004_tv', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_008_tv', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_040_sgn', 'regnety_064', 'regnety_080', 'regnety_080_tv', 'regnety_120', 'regnety_160', 'regnety_320', 'regnety_640', 'regnety_1280', 'regnety_2560', 'regnetz_005', 'regnetz_040', 'regnetz_040_h', 'regnetz_b16', 'regnetz_b16_evos', 'regnetz_c16', 'regnetz_c16_evos', 'regnetz_d8', 'regnetz_d8_evos', 'regnetz_d32', 'regnetz_e8', 'repghostnet_050', 'repghostnet_058', 'repghostnet_080', 'repghostnet_100', 'repghostnet_111', 'repghostnet_130', 'repghostnet_150', 'repghostnet_200', 'repvgg_a0', 'repvgg_a1', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'repvgg_d2se', 'repvit_m0_9', 'repvit_m1', 'repvit_m1_0', 'repvit_m1_1', 'repvit_m1_5', 'repvit_m2', 'repvit_m2_3', 'repvit_m3', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net50d', 'res2net101_26w_4s', 'res2net101d', 'res2next50', 'resmlp_12_224', 'resmlp_24_224', 'resmlp_36_224', 'resmlp_big_24_224', 'resnest14d', 'resnest26d', 'resnest50d', 'resnest50d_1s4x24d', 'resnest50d_4s2x40d', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet10t', 'resnet14t', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet26t', 'resnet32ts', 'resnet33ts', 'resnet34', 'resnet34d', 'resnet50', 'resnet50_clip', 'resnet50_clip_gap', 'resnet50_gn', 'resnet50_mlp', 'resnet50c', 'resnet50d', 'resnet50s', 'resnet50t', 'resnet50x4_clip', 'resnet50x4_clip_gap', 'resnet50x16_clip', 'resnet50x16_clip_gap', 'resnet50x64_clip', 'resnet50x64_clip_gap', 'resnet51q', 'resnet61q', 'resnet101', 'resnet101_clip', 'resnet101_clip_gap', 'resnet101c', 'resnet101d', 'resnet101s', 'resnet152', 'resnet152c', 'resnet152d', 'resnet152s', 'resnet200', 'resnet200d', 'resnetaa34d', 'resnetaa50', 'resnetaa50d', 'resnetaa101d', 'resnetblur18', 'resnetblur50', 'resnetblur50d', 'resnetblur101d', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_18', 'resnetv2_18d', 'resnetv2_34', 'resnetv2_34d', 'resnetv2_50', 'resnetv2_50d', 'resnetv2_50d_evos', 'resnetv2_50d_frn', 'resnetv2_50d_gn', 'resnetv2_50t', 'resnetv2_50x1_bit', 'resnetv2_50x3_bit', 'resnetv2_101', 'resnetv2_101d', 'resnetv2_101x1_bit', 'resnetv2_101x3_bit', 'resnetv2_152', 'resnetv2_152d', 'resnetv2_152x2_bit', 'resnetv2_152x4_bit', 'resnext26ts', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_64x4d', 'rexnet_100', 'rexnet_130', 'rexnet_150', 'rexnet_200', 'rexnet_300', 'rexnetr_100', 'rexnetr_130', 'rexnetr_150', 'rexnetr_200', 'rexnetr_300', 'sam2_hiera_base_plus', 'sam2_hiera_large', 'sam2_hiera_small', 'sam2_hiera_tiny', 'samvit_base_patch16', 'samvit_base_patch16_224', 'samvit_huge_patch16', 'samvit_large_patch16', 'sebotnet33ts_256', 'sedarknet21', 'sehalonet33ts', 'selecsls42', 'selecsls42b', 'selecsls60', 'selecsls60b', 'selecsls84', 'semnasnet_050', 'semnasnet_075', 'semnasnet_100', 'semnasnet_140', 'senet154', 'sequencer2d_l', 'sequencer2d_m', 'sequencer2d_s', 'seresnet18', 'seresnet33ts', 'seresnet34', 'seresnet50', 'seresnet50t', 'seresnet101', 'seresnet152', 'seresnet152d', 'seresnet200d', 'seresnet269d', 'seresnetaa50d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext26ts', 'seresnext50_32x4d', 'seresnext101_32x4d', 'seresnext101_32x8d', 'seresnext101_64x4d', 'seresnext101d_32x8d', 'seresnextaa101d_32x8d', 'seresnextaa201d_32x8d', 'skresnet18', 'skresnet34', 'skresnet50', 'skresnet50d', 'skresnext50_32x4d', 'spnasnet_100', 'swin_base_patch4_window7_224', 'swin_base_patch4_window12_384', 'swin_large_patch4_window7_224', 'swin_large_patch4_window12_384', 'swin_s3_base_224', 'swin_s3_small_224', 'swin_s3_tiny_224', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swinv2_base_window8_256', 'swinv2_base_window12_192', 'swinv2_base_window12to16_192to256', 'swinv2_base_window12to24_192to384', 'swinv2_base_window16_256', 'swinv2_cr_base_224', 'swinv2_cr_base_384', 'swinv2_cr_base_ns_224', 'swinv2_cr_giant_224', 'swinv2_cr_giant_384', 'swinv2_cr_huge_224', 'swinv2_cr_huge_384', 'swinv2_cr_large_224', 'swinv2_cr_large_384', 'swinv2_cr_small_224', 'swinv2_cr_small_384', 'swinv2_cr_small_ns_224', 'swinv2_cr_small_ns_256', 'swinv2_cr_tiny_224', 'swinv2_cr_tiny_384', 'swinv2_cr_tiny_ns_224', 'swinv2_large_window12_192', 'swinv2_large_window12to16_192to256', 'swinv2_large_window12to24_192to384', 'swinv2_small_window8_256', 'swinv2_small_window16_256', 'swinv2_tiny_window8_256', 'swinv2_tiny_window16_256', 'test_byobnet', 'test_convnext', 'test_convnext2', 'test_convnext3', 'test_efficientnet', 'test_efficientnet_evos', 'test_efficientnet_gn', 'test_efficientnet_ln', 'test_mambaout', 'test_nfnet', 'test_resnet', 'test_vit', 'test_vit2', 'test_vit3', 'test_vit4', 'tf_efficientnet_b0', 'tf_efficientnet_b1', 'tf_efficientnet_b2', 'tf_efficientnet_b3', 'tf_efficientnet_b4', 'tf_efficientnet_b5', 'tf_efficientnet_b6', 'tf_efficientnet_b7', 'tf_efficientnet_b8', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_m', 'tf_efficientnetv2_s', 'tf_efficientnetv2_xl', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tiny_vit_5m_224', 'tiny_vit_11m_224', 'tiny_vit_21m_224', 'tiny_vit_21m_384', 'tiny_vit_21m_512', 'tinynet_a', 'tinynet_b', 'tinynet_c', 'tinynet_d', 'tinynet_e', 'tnt_b_patch16_224', 'tnt_s_patch16_224', 'tresnet_l', 'tresnet_m', 'tresnet_v2_l', 'tresnet_xl', 'twins_pcpvt_base', 'twins_pcpvt_large', 'twins_pcpvt_small', 'twins_svt_base', 'twins_svt_large', 'twins_svt_small', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'visformer_small', 'visformer_tiny', 'vit_base_mci_224', 'vit_base_patch8_224', 'vit_base_patch14_dinov2', 'vit_base_patch14_reg4_dinov2', 'vit_base_patch16_18x2_224', 'vit_base_patch16_224', 'vit_base_patch16_224_miil', 'vit_base_patch16_384', 'vit_base_patch16_clip_224', 'vit_base_patch16_clip_384', 'vit_base_patch16_clip_quickgelu_224', 'vit_base_patch16_gap_224', 'vit_base_patch16_plus_240', 'vit_base_patch16_plus_clip_240', 'vit_base_patch16_reg4_gap_256', 'vit_base_patch16_rope_reg1_gap_256', 'vit_base_patch16_rpn_224', 'vit_base_patch16_siglip_224', 'vit_base_patch16_siglip_256', 'vit_base_patch16_siglip_384', 'vit_base_patch16_siglip_512', 'vit_base_patch16_siglip_gap_224', 'vit_base_patch16_siglip_gap_256', 'vit_base_patch16_siglip_gap_384', 'vit_base_patch16_siglip_gap_512', 'vit_base_patch16_xp_224', 'vit_base_patch32_224', 'vit_base_patch32_384', 'vit_base_patch32_clip_224', 'vit_base_patch32_clip_256', 'vit_base_patch32_clip_384', 'vit_base_patch32_clip_448', 'vit_base_patch32_clip_quickgelu_224', 'vit_base_patch32_plus_256', 'vit_base_r26_s32_224', 'vit_base_r50_s16_224', 'vit_base_r50_s16_384', 'vit_base_resnet26d_224', 'vit_base_resnet50d_224', 'vit_betwixt_patch16_gap_256', 'vit_betwixt_patch16_reg1_gap_256', 'vit_betwixt_patch16_reg4_gap_256', 'vit_betwixt_patch16_reg4_gap_384', 'vit_betwixt_patch16_rope_reg4_gap_256', 'vit_betwixt_patch32_clip_224', 'vit_giant_patch14_224', 'vit_giant_patch14_clip_224', 'vit_giant_patch14_dinov2', 'vit_giant_patch14_reg4_dinov2', 'vit_giant_patch16_gap_224', 'vit_gigantic_patch14_224', 'vit_gigantic_patch14_clip_224', 'vit_gigantic_patch14_clip_quickgelu_224', 'vit_huge_patch14_224', 'vit_huge_patch14_clip_224', 'vit_huge_patch14_clip_336', 'vit_huge_patch14_clip_378', 'vit_huge_patch14_clip_quickgelu_224', 'vit_huge_patch14_clip_quickgelu_378', 'vit_huge_patch14_gap_224', 'vit_huge_patch14_xp_224', 'vit_huge_patch16_gap_448', 'vit_intern300m_patch14_448', 'vit_large_patch14_224', 'vit_large_patch14_clip_224', 'vit_large_patch14_clip_336', 'vit_large_patch14_clip_quickgelu_224', 'vit_large_patch14_clip_quickgelu_336', 'vit_large_patch14_dinov2', 'vit_large_patch14_reg4_dinov2', 'vit_large_patch14_xp_224', 'vit_large_patch16_224', 'vit_large_patch16_384', 'vit_large_patch16_siglip_256', 'vit_large_patch16_siglip_384', 'vit_large_patch16_siglip_gap_256', 'vit_large_patch16_siglip_gap_384', 'vit_large_patch32_224', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_384', 'vit_little_patch16_reg1_gap_256', 'vit_little_patch16_reg4_gap_256', 'vit_medium_patch16_clip_224', 'vit_medium_patch16_gap_240', 'vit_medium_patch16_gap_256', 'vit_medium_patch16_gap_384', 'vit_medium_patch16_reg1_gap_256', 'vit_medium_patch16_reg4_gap_256', 'vit_medium_patch16_rope_reg1_gap_256', 'vit_medium_patch32_clip_224', 'vit_mediumd_patch16_reg4_gap_256', 'vit_mediumd_patch16_reg4_gap_384', 'vit_mediumd_patch16_rope_reg1_gap_256', 'vit_pwee_patch16_reg1_gap_256', 'vit_relpos_base_patch16_224', 'vit_relpos_base_patch16_cls_224', 'vit_relpos_base_patch16_clsgap_224', 'vit_relpos_base_patch16_plus_240', 'vit_relpos_base_patch16_rpn_224', 'vit_relpos_base_patch32_plus_rpn_256', 'vit_relpos_medium_patch16_224', 'vit_relpos_medium_patch16_cls_224', 'vit_relpos_medium_patch16_rpn_224', 'vit_relpos_small_patch16_224', 'vit_relpos_small_patch16_rpn_224', 'vit_small_patch8_224', 'vit_small_patch14_dinov2', 'vit_small_patch14_reg4_dinov2', 'vit_small_patch16_18x2_224', 'vit_small_patch16_36x1_224', 'vit_small_patch16_224', 'vit_small_patch16_384', 'vit_small_patch32_224', 'vit_small_patch32_384', 'vit_small_r26_s32_224', 'vit_small_r26_s32_384', 'vit_small_resnet26d_224', 'vit_small_resnet50d_s16_224', 'vit_so150m2_patch16_reg1_gap_256', 'vit_so150m_patch16_reg4_gap_256', 'vit_so150m_patch16_reg4_gap_384', 'vit_so150m_patch16_reg4_map_256', 'vit_so400m_patch14_siglip_224', 'vit_so400m_patch14_siglip_378', 'vit_so400m_patch14_siglip_384', 'vit_so400m_patch14_siglip_gap_224', 'vit_so400m_patch14_siglip_gap_378', 'vit_so400m_patch14_siglip_gap_384', 'vit_so400m_patch14_siglip_gap_448', 'vit_so400m_patch14_siglip_gap_896', 'vit_so400m_patch16_siglip_256', 'vit_so400m_patch16_siglip_gap_256', 'vit_srelpos_medium_patch16_224', 'vit_srelpos_small_patch16_224', 'vit_tiny_patch16_224', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_384', 'vit_wee_patch16_reg1_gap_256', 'vit_xsmall_patch16_clip_224', 'vitamin_base_224', 'vitamin_large2_224', 'vitamin_large2_256', 'vitamin_large2_336', 'vitamin_large2_384', 'vitamin_large_224', 'vitamin_large_256', 'vitamin_large_336', 'vitamin_large_384', 'vitamin_small_224', 'vitamin_xlarge_256', 'vitamin_xlarge_336', 'vitamin_xlarge_384', 'volo_d1_224', 'volo_d1_384', 'volo_d2_224', 'volo_d2_384', 'volo_d3_224', 'volo_d3_448', 'volo_d4_224', 'volo_d4_448', 'volo_d5_224', 'volo_d5_448', 'volo_d5_512', 'vovnet39a', 'vovnet57a', 'wide_resnet50_2', 'wide_resnet101_2', 'xception41', 'xception41p', 'xception65', 'xception65p', 'xception71', 'xcit_large_24_p8_224', 'xcit_large_24_p8_384', 'xcit_large_24_p16_224', 'xcit_large_24_p16_384', 'xcit_medium_24_p8_224', 'xcit_medium_24_p8_384', 'xcit_medium_24_p16_224', 'xcit_medium_24_p16_384', 'xcit_nano_12_p8_224', 'xcit_nano_12_p8_384', 'xcit_nano_12_p16_224', 'xcit_nano_12_p16_384', 'xcit_small_12_p8_224', 'xcit_small_12_p8_384', 'xcit_small_12_p16_224', 'xcit_small_12_p16_384', 'xcit_small_24_p8_224', 'xcit_small_24_p8_384', 'xcit_small_24_p16_224', 'xcit_small_24_p16_384', 'xcit_tiny_12_p8_224', 'xcit_tiny_12_p8_384', 'xcit_tiny_12_p16_224', 'xcit_tiny_12_p16_384', 'xcit_tiny_24_p8_224', 'xcit_tiny_24_p8_384', 'xcit_tiny_24_p16_224', 'xcit_tiny_24_p16_384']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    DATA_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/A(train)/images\"\n",
        "    MASKS_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/A(train)/masks\"\n",
        "    METADATA_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/HAM10000_metadata\"\n",
        "    SAVE_MODEL_DIR = \"/content/drive/MyDrive/Medical_CV//피부암 분류 및 Segmentation/part3_datasets\"\n",
        "    SAVE_MASKS_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/B(test)/mask이미지(Segmentation_TransformerUNet)\"\n",
        "    TEST_DIR = \"/content/drive/MyDrive/Medical_CV/피부암 분류 및 Segmentation/main(A,B)/B(test)/images\"\n",
        "    BATCH_SIZE = 16\n",
        "    IMAGE_SIZE = (224, 224)\n",
        "    NUM_CLASSES = 1  # Binary Segmentation\n",
        "    EPOCHS = 20\n",
        "    LR = 1e-4\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "wsxEGD9GpMvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, metadata, image_transform=None, mask_transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.metadata = metadata\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 이미지 경로 설정\n",
        "        img_name = self.metadata.iloc[idx]['image_id']\n",
        "        image_path = os.path.join(self.image_dir, img_name + \".jpg\")\n",
        "        mask_path = os.path.join(self.mask_dir, img_name + \"_segmentation.png\")\n",
        "\n",
        "        # 이미지와 마스크 로드\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")  # Grayscale로 로드\n",
        "\n",
        "        # 마스크 이진화 (NumPy 배열로 변환 후 0과 1로 구성)\n",
        "        mask = np.array(mask)\n",
        "        mask = (mask > 128).astype(np.float32)  # 이진화 수행\n",
        "\n",
        "        # 변환 적용\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(Image.fromarray(mask * 255))  # NumPy 배열을 PIL 이미지로 변환 후 적용\n",
        "\n",
        "        # 마스크 채널 차원 추가 (필요한 경우)\n",
        "        if len(mask.shape) == 2:\n",
        "            mask = torch.unsqueeze(torch.tensor(mask), dim=0)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "vfKVlDrhqRDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(metadata_path, image_dir):\n",
        "    # 메타데이터 로드\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "    # 실제 파일과 매칭\n",
        "    image_files = set([f.split('.')[0] for f in os.listdir(image_dir)])\n",
        "    metadata = metadata[metadata['image_id'].isin(image_files)]\n",
        "\n",
        "    # 데이터 분할 (7:1.5:1.5)\n",
        "    train_data, temp_data = train_test_split(metadata, test_size=0.3, random_state=42, stratify=metadata['dx'])\n",
        "    val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['dx'])\n",
        "\n",
        "    return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "o656kVHU9uH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_transforms():\n",
        "    # 이미지에만 적용할 변환 (정규화 포함)\n",
        "    image_transform = T.Compose([\n",
        "        T.Resize(Config.IMAGE_SIZE),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "    # 마스크에만 적용할 변환 (정규화 없음)\n",
        "    mask_transform = T.Compose([\n",
        "        T.Resize(Config.IMAGE_SIZE),\n",
        "        T.ToTensor()  # 이진 마스크는 [0, 1] 범위로 변환됨\n",
        "    ])\n",
        "\n",
        "    return image_transform, mask_transform\n"
      ],
      "metadata": {
        "id": "F2e23XpnqQ_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerUNet(nn.Module):\n",
        "    def __init__(self, input_channels=3, output_channels=1):\n",
        "        super(TransformerUNet, self).__init__()\n",
        "\n",
        "        # MobileViT-XX Small 인코더\n",
        "        self.encoder = timm.create_model(\n",
        "            'mobilevit_xxs',\n",
        "            pretrained=True,\n",
        "            features_only=True,\n",
        "            in_chans=input_channels\n",
        "        )\n",
        "\n",
        "        # 인코더의 채널 수 가져오기\n",
        "        encoder_channels = self.encoder.feature_info.channels()\n",
        "\n",
        "        # 디코더 레이어들\n",
        "        self.decoder4 = self._decoder_block(encoder_channels[-1] + encoder_channels[-2], 512)\n",
        "        self.decoder3 = self._decoder_block(512 + encoder_channels[-3], 256)\n",
        "        self.decoder2 = self._decoder_block(256 + encoder_channels[-4], 128)\n",
        "        self.decoder1 = self._decoder_block(128 + encoder_channels[-5], 64)\n",
        "\n",
        "        # 최종 출력 레이어\n",
        "        self.final_conv = nn.Conv2d(64, output_channels, kernel_size=1)\n",
        "\n",
        "    def _decoder_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(out_channels, out_channels, 2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 인코더 통과\n",
        "        features = self.encoder(x)\n",
        "\n",
        "        # 디코더 통과 (스킵 커넥션 활용)\n",
        "        x = self.decoder4(torch.cat([features[-1],\n",
        "            F.interpolate(features[-2], size=features[-1].shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "        x = self.decoder3(torch.cat([x,\n",
        "            F.interpolate(features[-3], size=x.shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "        x = self.decoder2(torch.cat([x,\n",
        "            F.interpolate(features[-4], size=x.shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "        x = self.decoder1(torch.cat([x,\n",
        "            F.interpolate(features[-5], size=x.shape[2:], mode='bilinear', align_corners=False)], dim=1))\n",
        "\n",
        "        # 최종 출력\n",
        "        x = self.final_conv(x)\n",
        "        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vsLiSdaicBx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, num_epochs=20, learning_rate=1e-4, patience=5):\n",
        "    \"\"\"\n",
        "    모델 학습을 수행하는 함수\n",
        "\n",
        "    Args:\n",
        "        model: 학습할 모델\n",
        "        train_loader: 학습 데이터 로더\n",
        "        val_loader: 검증 데이터 로더\n",
        "        device: 학습에 사용할 디바이스 (cuda/cpu)\n",
        "        num_epochs: 학습 에포크 수\n",
        "        learning_rate: 학습률\n",
        "        patience: Early stopping을 위한 patience 값\n",
        "\n",
        "    Returns:\n",
        "        model: 학습된 모델\n",
        "        best_model_state: 가장 좋은 성능을 보인 모델의 가중치\n",
        "        history: 학습 히스토리\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.BCEWithLogitsLoss()  # 손실 함수: BCEWithLogitsLoss\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "    # 학습 관련 변수 초기화\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    early_stopping_counter = 0\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_dice': [],\n",
        "        'val_dice': []\n",
        "    }\n",
        "\n",
        "    print(\"Starting training process...\")\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ----------------------\n",
        "        # Training phase\n",
        "        # ----------------------\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_intersection = 0\n",
        "        train_union = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Training]')\n",
        "\n",
        "        for images, masks in progress_bar:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 손실값 및 Dice coefficient 계산\n",
        "            train_loss += loss.item()\n",
        "            predicted_masks = (outputs > 0).float()  # BCEWithLogitsLoss 사용 시 0 기준\n",
        "            intersection = (predicted_masks * masks).sum()\n",
        "            union = predicted_masks.sum() + masks.sum()\n",
        "            train_intersection += intersection.item()\n",
        "            train_union += union.item()\n",
        "            train_batches += 1\n",
        "\n",
        "            # 프로그레스바 업데이트\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'dice': f'{(2 * intersection / (union + 1e-8)).item():.4f}'\n",
        "            })\n",
        "\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        avg_train_dice = (2 * train_intersection) / (train_union + 1e-8)\n",
        "\n",
        "        # ----------------------\n",
        "        # Validation phase\n",
        "        # ----------------------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_intersection = 0\n",
        "        val_union = 0\n",
        "        val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Validation]')\n",
        "\n",
        "            for images, masks in progress_bar:\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                predicted_masks = (outputs > 0).float()\n",
        "                intersection = (predicted_masks * masks).sum()\n",
        "                union = predicted_masks.sum() + masks.sum()\n",
        "                val_intersection += intersection.item()\n",
        "                val_union += union.item()\n",
        "                val_batches += 1\n",
        "\n",
        "                progress_bar.set_postfix({\n",
        "                    'val_loss': f'{loss.item():.4f}',\n",
        "                    'val_dice': f'{(2 * intersection / (union + 1e-8)).item():.4f}'\n",
        "                })\n",
        "\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        avg_val_dice = (2 * val_intersection) / (val_union + 1e-8)\n",
        "\n",
        "        # 히스토리 업데이트\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['train_dice'].append(avg_train_dice)\n",
        "        history['val_dice'].append(avg_val_dice)\n",
        "\n",
        "        # 결과 출력\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Dice: {avg_train_dice:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Dice: {avg_val_dice:.4f}\")\n",
        "\n",
        "        # 학습률 스케줄러 호출\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # 최적 모델 저장\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            early_stopping_counter = 0\n",
        "            print(f\"Best model updated at epoch {epoch+1}\")\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "\n",
        "        # Early stopping 체크\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "        # 중간 체크포인트 저장 (5 에포크마다)\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint_path = os.path.join(\n",
        "                Config.SAVE_MODEL_DIR,\n",
        "                f'checkpoint_epoch_{epoch+1}.pth'\n",
        "            )\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "                'train_dice': avg_train_dice,\n",
        "                'val_dice': avg_val_dice,\n",
        "                'history': history\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, best_model_state, history"
      ],
      "metadata": {
        "id": "AqwJ390-5e4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(save_dir, model_state, file_name=\"best_model.pth\"):\n",
        "    \"\"\"\n",
        "    모델 가중치를 저장하는 함수.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, file_name)\n",
        "    torch.save(model_state, save_path)\n",
        "    print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "id": "Nyd25q7Y5iXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 분리\n",
        "train_data, val_data, test_data = split_data(Config.METADATA_DIR, Config.DATA_DIR)\n",
        "\n",
        "# 2. 데이터 로드 및 변환\n",
        "image_transform, mask_transform = get_data_transforms()\n",
        "\n",
        "train_dataset = ImageDataset(Config.DATA_DIR, Config.MASKS_DIR, train_data, image_transform, mask_transform)\n",
        "val_dataset = ImageDataset(Config.DATA_DIR, Config.MASKS_DIR, val_data, image_transform, mask_transform)\n",
        "test_dataset = ImageDataset(Config.DATA_DIR, Config.MASKS_DIR, test_data, image_transform, mask_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "zISr99W75iVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, masks in train_loader:\n",
        "    print(f\"Image batch shape: {images.shape}\")  # 이미지 형태 출력\n",
        "    print(f\"Mask batch shape: {masks.shape}\")    # 마스크 형태 출력\n",
        "    break  # 첫 번째 배치만 출력하고 종료"
      ],
      "metadata": {
        "id": "8D90BXXO5juH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a243ac-808b-41d9-8db9-5205f44bead3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape: torch.Size([16, 3, 224, 224])\n",
            "Mask batch shape: torch.Size([16, 1, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7uz5MhhQvRt",
        "outputId": "820c3c89-d466-41bd-dced-a97a8708e9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 학습\n",
        "model = TransformerUNet(input_channels=3, output_channels=1)\n",
        "trained_model, best_model_state, history = train_model(model, train_loader, val_loader, Config.DEVICE)\n",
        "\n",
        "# 최적 모델 저장\n",
        "save_path = os.path.join(Config.SAVE_MODEL_DIR, \"best_model_mobilevit.pth\")\n",
        "torch.save(best_model_state, save_path)\n",
        "print(f\"Best model saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dc3e5098b3b342af89cf8d6f4a094f5f",
            "9cc7f9953c2c4218a832612d81101d27",
            "69ab3ea182394f5c9346cdbeebe32b28",
            "a27b449cdcff4500afc6a5b445a165f7",
            "f5bda6d549144c7a896da47c1c8304d4",
            "ba69654b79594a9b997569a5682e919a",
            "9a5cc6ef7c494cba8f109dbc2f1b62a9",
            "37170b1fedfc497b9e3cfb39450c585f",
            "bed56802899b4339bfbdbea51a79718e",
            "0de2dfde2e734eb8877414f65c1a489b",
            "f50d08f589944390bffccab21d6e8c08"
          ]
        },
        "id": "N-TjJReqQvPg",
        "outputId": "6627e953-f163-4e92-b7a7-faaf4b7d6aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.14M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc3e5098b3b342af89cf8d6f4a094f5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training process...\n",
            "Training on device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20 [Training]: 100%|██████████| 395/395 [53:44<00:00,  8.16s/it, loss=-2669.6582, dice=1.9653]\n",
            "Epoch 1/20 [Validation]: 100%|██████████| 85/85 [10:07<00:00,  7.14s/it, val_loss=-1642.8398, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20:\n",
            "Train Loss: -1048.8900, Train Dice: 1.9455\n",
            "Val Loss: -2827.4059, Val Dice: 1.9710\n",
            "Best model updated at epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20 [Training]: 100%|██████████| 395/395 [02:56<00:00,  2.24it/s, loss=-12674.2949, dice=1.9832]\n",
            "Epoch 2/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.80it/s, val_loss=-5599.4131, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/20:\n",
            "Train Loss: -6409.1468, Train Dice: 1.9712\n",
            "Val Loss: -10047.0322, Val Dice: 1.9710\n",
            "Best model updated at epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20 [Training]: 100%|██████████| 395/395 [02:51<00:00,  2.30it/s, loss=-23388.0781, dice=1.9662]\n",
            "Epoch 3/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.81it/s, val_loss=-15001.4248, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/20:\n",
            "Train Loss: -17204.3123, Train Dice: 1.9712\n",
            "Val Loss: -23865.3181, Val Dice: 1.9710\n",
            "Best model updated at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20 [Training]: 100%|██████████| 395/395 [02:50<00:00,  2.32it/s, loss=-29929.7207, dice=1.9408]\n",
            "Epoch 4/20 [Validation]: 100%|██████████| 85/85 [00:31<00:00,  2.72it/s, val_loss=-28156.8594, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/20:\n",
            "Train Loss: -34210.1330, Train Dice: 1.9712\n",
            "Val Loss: -49006.7002, Val Dice: 1.9710\n",
            "Best model updated at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20 [Training]: 100%|██████████| 395/395 [02:51<00:00,  2.30it/s, loss=-60149.7344, dice=1.9571]\n",
            "Epoch 5/20 [Validation]: 100%|██████████| 85/85 [00:31<00:00,  2.71it/s, val_loss=-45990.7891, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/20:\n",
            "Train Loss: -57982.2829, Train Dice: 1.9712\n",
            "Val Loss: -71779.1714, Val Dice: 1.9710\n",
            "Best model updated at epoch 5\n",
            "Checkpoint saved at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20 [Training]: 100%|██████████| 395/395 [02:50<00:00,  2.31it/s, loss=-88724.9922, dice=1.9627]\n",
            "Epoch 6/20 [Validation]: 100%|██████████| 85/85 [00:29<00:00,  2.90it/s, val_loss=-72434.8359, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/20:\n",
            "Train Loss: -89026.8631, Train Dice: 1.9712\n",
            "Val Loss: -112283.1151, Val Dice: 1.9710\n",
            "Best model updated at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20 [Training]: 100%|██████████| 395/395 [02:52<00:00,  2.29it/s, loss=-149523.7031, dice=1.9718]\n",
            "Epoch 7/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.82it/s, val_loss=-93528.2031, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/20:\n",
            "Train Loss: -127615.9542, Train Dice: 1.9712\n",
            "Val Loss: -144706.6124, Val Dice: 1.9710\n",
            "Best model updated at epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20 [Training]: 100%|██████████| 395/395 [02:50<00:00,  2.31it/s, loss=-230586.3125, dice=1.9800]\n",
            "Epoch 8/20 [Validation]: 100%|██████████| 85/85 [00:29<00:00,  2.85it/s, val_loss=-117925.2109, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/20:\n",
            "Train Loss: -174194.1444, Train Dice: 1.9712\n",
            "Val Loss: -187637.3681, Val Dice: 1.9710\n",
            "Best model updated at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20 [Training]: 100%|██████████| 395/395 [02:51<00:00,  2.31it/s, loss=-251491.2188, dice=1.9694]\n",
            "Epoch 9/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.77it/s, val_loss=-160214.5469, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/20:\n",
            "Train Loss: -228380.0911, Train Dice: 1.9712\n",
            "Val Loss: -249827.4542, Val Dice: 1.9710\n",
            "Best model updated at epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20 [Training]: 100%|██████████| 395/395 [02:51<00:00,  2.30it/s, loss=-256197.3750, dice=1.9536]\n",
            "Epoch 10/20 [Validation]: 100%|██████████| 85/85 [00:29<00:00,  2.88it/s, val_loss=-212878.5000, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/20:\n",
            "Train Loss: -290475.5548, Train Dice: 1.9712\n",
            "Val Loss: -335195.6235, Val Dice: 1.9710\n",
            "Best model updated at epoch 10\n",
            "Checkpoint saved at epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20 [Training]: 100%|██████████| 395/395 [02:54<00:00,  2.26it/s, loss=-428219.5625, dice=1.9749]\n",
            "Epoch 11/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.83it/s, val_loss=-233167.4375, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11/20:\n",
            "Train Loss: -362120.8385, Train Dice: 1.9712\n",
            "Val Loss: -378030.8493, Val Dice: 1.9710\n",
            "Best model updated at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20 [Training]: 100%|██████████| 395/395 [02:52<00:00,  2.29it/s, loss=-399436.8438, dice=1.9557]\n",
            "Epoch 12/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.81it/s, val_loss=-294965.8125, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12/20:\n",
            "Train Loss: -441782.2631, Train Dice: 1.9712\n",
            "Val Loss: -457521.7827, Val Dice: 1.9710\n",
            "Best model updated at epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20 [Training]: 100%|██████████| 395/395 [02:53<00:00,  2.28it/s, loss=-537394.1875, dice=1.9673]\n",
            "Epoch 13/20 [Validation]: 100%|██████████| 85/85 [00:29<00:00,  2.87it/s, val_loss=-369746.1875, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13/20:\n",
            "Train Loss: -530955.5623, Train Dice: 1.9712\n",
            "Val Loss: -564623.4140, Val Dice: 1.9710\n",
            "Best model updated at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20 [Training]: 100%|██████████| 395/395 [02:51<00:00,  2.30it/s, loss=-770627.0625, dice=1.9781]\n",
            "Epoch 14/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.78it/s, val_loss=-431595.4062, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14/20:\n",
            "Train Loss: -628377.5032, Train Dice: 1.9712\n",
            "Val Loss: -656372.5893, Val Dice: 1.9710\n",
            "Best model updated at epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20 [Training]: 100%|██████████| 395/395 [02:51<00:00,  2.31it/s, loss=-885827.7500, dice=1.9769]\n",
            "Epoch 15/20 [Validation]: 100%|██████████| 85/85 [00:29<00:00,  2.87it/s, val_loss=-494857.5000, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15/20:\n",
            "Train Loss: -736847.2345, Train Dice: 1.9712\n",
            "Val Loss: -751178.5007, Val Dice: 1.9710\n",
            "Best model updated at epoch 15\n",
            "Checkpoint saved at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20 [Training]: 100%|██████████| 395/395 [02:53<00:00,  2.28it/s, loss=-793963.2500, dice=1.9609]\n",
            "Epoch 16/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.82it/s, val_loss=-588856.7500, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16/20:\n",
            "Train Loss: -853836.3851, Train Dice: 1.9712\n",
            "Val Loss: -894633.3618, Val Dice: 1.9710\n",
            "Best model updated at epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20 [Training]: 100%|██████████| 395/395 [02:51<00:00,  2.30it/s, loss=-777227.5000, dice=1.9495]\n",
            "Epoch 17/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.80it/s, val_loss=-679546.8750, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17/20:\n",
            "Train Loss: -981182.6603, Train Dice: 1.9712\n",
            "Val Loss: -1053100.4735, Val Dice: 1.9710\n",
            "Best model updated at epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20 [Training]: 100%|██████████| 395/395 [02:55<00:00,  2.25it/s, loss=-1213098.0000, dice=1.9719]\n",
            "Epoch 18/20 [Validation]: 100%|██████████| 85/85 [00:30<00:00,  2.83it/s, val_loss=-751304.7500, val_dice=1.9578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18/20:\n",
            "Train Loss: -1119830.1217, Train Dice: 1.9712\n",
            "Val Loss: -1123304.0522, Val Dice: 1.9710\n",
            "Best model updated at epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20 [Training]:  80%|███████▉  | 315/395 [02:18<00:34,  2.34it/s, loss=-1219635.7500, dice=1.9665]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train vs Validation Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Train vs Validation Dice Coefficient\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history['train_dice'], label='Train Dice')\n",
        "plt.plot(history['val_dice'], label='Val Dice')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.title('Train vs Validation Dice Coefficient')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5PhZSfPCQvNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_id = self.image_files[idx].split('.')[0]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, image_id"
      ],
      "metadata": {
        "id": "m459Z9W1SXnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_masks(model, data_loader, save_dir, device):\n",
        "    model.eval()\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"Generating masks\"):\n",
        "            images, image_ids = batch\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            predictions = torch.sigmoid(outputs) > 0.5  # sigmoid 적용 후 이진화\n",
        "\n",
        "            for pred, img_id in zip(predictions, image_ids):\n",
        "                mask = pred.squeeze().cpu().numpy() * 255\n",
        "                mask_path = os.path.join(save_dir, f\"{img_id}_generated.png\")\n",
        "                cv2.imwrite(mask_path, mask.astype(np.uint8))\n",
        "\n",
        "    print(f\"Masks saved to {save_dir}\")"
      ],
      "metadata": {
        "id": "1eH4rF8_SXlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 이미지 경로\n",
        "test_image_dir = Config.TEST_DIR\n",
        "\n",
        "# 변환 정의 (학습에 사용한 것과 동일하게 적용)\n",
        "test_transform = T.Compose([\n",
        "    T.Resize(Config.IMAGE_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# 테스트 데이터셋 및 데이터 로더 생성\n",
        "Test_Dataset = TestImageDataset(test_image_dir, transform=test_transform)\n",
        "Test_Loader = DataLoader(Test_Dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2,\n",
        "                        pin_memory=True)\n",
        "\n",
        "# 학습된 모델로 테스트 데이터에 대한 마스크 생성 및 저장\n",
        "generate_and_save_masks(trained_model, Test_Loader, Config.SAVE_MASKS_DIR, Config.DEVICE)"
      ],
      "metadata": {
        "id": "33bvIephSadb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}